{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI & Machine Learning (KAN-CINTO4003U) - Copenhagen Business School | Spring 2025**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part I: Bag-of-Words Model\n",
    "\n",
    "Please see the description of the assignment in the README file (section 1) <br>\n",
    "**Guide notebook**: [guides/bow_guide.ipynb](guides/bow_guide.ipynb)\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "* Note that you should report results using a classification report. \n",
    "\n",
    "* Also, remember to include some reflections on your results: Are there any hyperparameters that are particularly important?\n",
    "\n",
    "* You should follow the steps given in the `bow_guide` notebook\n",
    "\n",
    "<br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for the project\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data\n",
    "\n",
    "We can load this data directly from [Hugging Face Datasets](https://huggingface.co/docs/datasets/) - The HuggingFace Hub- into a Pandas DataFrame. Pretty neat!\n",
    "\n",
    "**Note**: This cell will download the dataset and keep it in memory. If you run this cell multiple times, it will download the dataset multiple times.\n",
    "\n",
    "You are welcome to increase the `frac` parameter to load more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 2) (7600, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "\n",
    "train = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"train\"])\n",
    "test = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"test\"])\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2400, 2), (1520, 2))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "label_map = {\n",
    "    0: 'World',\n",
    "    1: 'Sports',\n",
    "    2: 'Business',\n",
    "    3: 'Sci/Tech'\n",
    "}\n",
    "\n",
    "def preprocess(df: pd.DataFrame, frac : float = 1e-2, label_map : dict[int, str] = label_map, seed : int = 42) -> pd.DataFrame:\n",
    "    \"\"\" Preprocess the dataset \n",
    "\n",
    "    Operations:\n",
    "    - Map the label to the corresponding category\n",
    "    - Filter out the labels not in the label_map\n",
    "    - Sample a fraction of the dataset (stratified by label)\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): The dataset to preprocess\n",
    "    - frac (float): The fraction of the dataset to sample in each category\n",
    "    - label_map (dict): A mapping of the original label to the new label\n",
    "    - seed (int): The random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The preprocessed dataset\n",
    "    \"\"\"\n",
    "\n",
    "    return  (\n",
    "        df\n",
    "        .assign(label=lambda x: x['label'].map(label_map))\n",
    "        [lambda df: df['label'].isin(label_map.values())]\n",
    "        .groupby('label')[[\"text\", \"label\"]]\n",
    "        .apply(lambda x: x.sample(frac=frac, random_state=seed))\n",
    "        .reset_index(drop=True)\n",
    "\n",
    "    )\n",
    "\n",
    "train_df = preprocess(train, frac=0.02)\n",
    "test_df = preprocess(test, frac=0.2)\n",
    "\n",
    "# clear up some memory by deleting the original dataframes\n",
    "del train\n",
    "del test\n",
    "\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920,) (480,) (1920,) (480,)\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    \n",
    "    X_train,\n",
    "    X_val,\n",
    "    y_train,\n",
    "    y_val\n",
    "\n",
    ") = train_test_split(train_df[\"text\"], train_df[\"label\"], test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced CountVectorizer with better parameters\n",
    "cv = CountVectorizer(\n",
    "    min_df=3,           # Ignore terms that appear in less than 2 documents\n",
    "    max_df=0.9,         # Ignore terms that appear in more than 90% of documents\n",
    "    ngram_range=(1, 2)  # Include both unigrams and bigrams\n",
    ")\n",
    "X_train_vectorized = cv.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best parameters: {'C': 0.1, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.05, 0.1, 0.5, 1.0],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# Create a grid search object\n",
    "grid_search = GridSearchCV(\n",
    "    LogisticRegression(random_state=42, max_iter=1000),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Use the best model\n",
    "best_lr_clf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr_clf = LogisticRegression() # Note that we can set hyperparameters here\n",
    "\n",
    "lr_clf.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_vectorized = cv.transform(X_val) \n",
    "\n",
    "y_pred = best_lr_clf.predict(X_val_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on the training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World       0.99      0.99      0.99       474\n",
      "      Sports       0.99      0.99      0.99       478\n",
      "    Business       0.99      1.00      0.99       485\n",
      "    Sci/Tech       1.00      0.99      0.99       483\n",
      "\n",
      "    accuracy                           0.99      1920\n",
      "   macro avg       0.99      0.99      0.99      1920\n",
      "weighted avg       0.99      0.99      0.99      1920\n",
      "\n",
      "Performance on the validation set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World       0.78      0.71      0.75       126\n",
      "      Sports       0.76      0.75      0.75       122\n",
      "    Business       0.78      0.92      0.84       115\n",
      "    Sci/Tech       0.84      0.79      0.81       117\n",
      "\n",
      "    accuracy                           0.79       480\n",
      "   macro avg       0.79      0.79      0.79       480\n",
      "weighted avg       0.79      0.79      0.79       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Performance on the training set:\")\n",
    "print(classification_report(y_train, best_lr_clf.predict(X_train_vectorized), target_names=label_map.values()))\n",
    "\n",
    "print(\"Performance on the validation set:\")\n",
    "print(classification_report(y_val, y_pred, target_names=label_map.values()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World       0.78      0.80      0.79       380\n",
      "      Sports       0.81      0.79      0.80       380\n",
      "    Business       0.87      0.91      0.89       380\n",
      "    Sci/Tech       0.86      0.81      0.83       380\n",
      "\n",
      "    accuracy                           0.83      1520\n",
      "   macro avg       0.83      0.83      0.83      1520\n",
      "weighted avg       0.83      0.83      0.83      1520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df_vectorized = cv.transform(test_df[\"text\"])\n",
    "\n",
    "print(\"Performance on the test set:\")\n",
    "print(classification_report(test_df[\"label\"], best_lr_clf.predict(test_df_vectorized), target_names=label_map.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflections on Results and Hyperparameter Choices\n",
    "\n",
    "\n",
    "My implementation of the Bag-of-Words model with optimized hyperparameters achieved 79% accuracy on the validation set and 83% on the test set, a significant improvement over the lg model in the guide notebook (76% validation, 78% test).\n",
    "\n",
    "### Key Hyperparameter Optimizations\n",
    "\n",
    "1. **CountVectorizer Enhancements:**\n",
    "   - Setting min_df=3 removed rare terms that could introduce noise\n",
    "   - Using max_df=0.9 filtered out extremely common words that provide little discriminative value\n",
    "   - Including bigrams (ngram_range=(1,2)) captured important word combinations and context\n",
    "\n",
    "2. **Logistic Regression Tuning:**\n",
    "   - Grid search identified optimal hyperparameters: C=0.1, penalty='l2', solver='saga', class_weight=None\n",
    "   - The lower C value (0.1) increased regularization, reducing overfitting compared to the default (C=1.0)\n",
    "\n",
    "### Performance Analysis\n",
    "\n",
    "The optimized model shows:\n",
    "- Reduced overfitting (training accuracy 99% vs. validation 79%)\n",
    "- Overall balanced precision and recall across all categories\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The hyperparameter tuning process demonstrated that feature representation (through CountVectorizer settings) and regularization strength (C value) were the most impactful factors for model performance. The inclusion of bigrams and careful filtering of vocabulary significantly improved the model's ability to capture relevant patterns in the text data.\n",
    "\n",
    "This exercise highlights the importance of systematic hyperparameter optimization in NLP tasks, even with relatively simple models like Bag-of-Words with logistic regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml25-ma1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
